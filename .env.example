# DevLifecycle Crew Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM Configuration (Required)
# =============================================================================

# OpenAI API Key (required for default configuration)
OPENAI_API_KEY=your-openai-api-key-here

# OpenAI Model to use (default: gpt-4o)
OPENAI_MODEL=gpt-4o

# Temperature for LLM responses (0.0 - 1.0, default: 0.7)
TEMPERATURE=0.7

# Alternative: Anthropic API Key (if using Claude)
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# =============================================================================
# Application Settings
# =============================================================================

# Enable verbose output (default: True)
VERBOSE=True

# Maximum requests per minute to LLM (default: 10)
MAX_RPM=10

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# =============================================================================
# Storage Configuration
# =============================================================================

# Database URL for persistent storage
DATABASE_URL=sqlite:///devlifecycle.db

# =============================================================================
# External Integrations (Optional)
# =============================================================================

# Jira Integration
# JIRA_URL=https://your-company.atlassian.net
# JIRA_EMAIL=your-email@company.com
# JIRA_API_TOKEN=your-jira-api-token

# GitHub Integration
# GITHUB_TOKEN=your-github-token
# GITHUB_REPO=owner/repo-name
